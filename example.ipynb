{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6scejnyTh/fOzopxGVCu8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raneye99/COMP0087/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBdyhbwbl167",
        "outputId": "1d496845-ae02-4a43-dd63-c9edd7258f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "changing directory to: /content/drive/MyDrive/NLP/COMP0087\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Updating 3319a47..1260e78\n",
            "Fast-forward\n",
            " example.ipynb          | 141 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
            " mosei_model_load.ipynb |  22 ++++++--\n",
            " mtl/data_utils.py      |  64 ++++++++++++++++++++++\n",
            " test.ipynb             |  67 +++++++++++++++++++++++\n",
            " 4 files changed, 291 insertions(+), 3 deletions(-)\n",
            " create mode 100644 example.ipynb\n",
            " create mode 100644 mtl/data_utils.py\n",
            " create mode 100644 test.ipynb\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#set up\n",
        "gdrive_location = \"/content/drive/MyDrive/NLP\"\n",
        "pat_file = \"pat.json\"\n",
        "import subprocess\n",
        "import json\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "gdrive_mount = '/content/drive'\n",
        "# requires giving access to google drive account\n",
        "drive.mount(gdrive_mount)\n",
        "\n",
        "# change to relevant workspace \n",
        "# - google drive dir - where 'pat_file' should be found\n",
        "gdrive_dir = os.path.join(gdrive_mount, gdrive_location)\n",
        "work_dir = gdrive_dir\n",
        "\n",
        "#url for repo\n",
        "url = \":x-oauth-basic@github.com/raneye99/COMP0087\"\n",
        "\n",
        "#repo directory\n",
        "repo_dir = os.path.join(gdrive_dir, os.path.basename(url))\n",
        "\n",
        "# change to working directory\n",
        "# os.chdir(work_dir)\n",
        "assert os.path.exists(work_dir), f\"workspace directory: {work_dir} does not exist\"\n",
        "os.chdir(work_dir)\n",
        "# this is a bit long - would be good to reduce\n",
        "# if git directory does not exist - clone \n",
        "if not os.path.exists(repo_dir):\n",
        "    # get pat file - expected to be in work_dir\n",
        "    # pat expected to be dict: {\"pat\": \"<personal access token>\"}\n",
        "    with open(os.path.join(gdrive_dir, pat_file), \"r+\") as f:\n",
        "        pat = json.load(f)\n",
        "\n",
        "    # git clone\n",
        "    print(f\"cloning directory: {url}\")\n",
        "    git_clone = subprocess.check_output( [\"git\", \"clone\", f\"https://{pat['pat']}{url}\"] , shell=False)\n",
        "    print(git_clone)\n",
        "\n",
        "print(f\"changing directory to: {repo_dir}\")\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "# --\n",
        "# change branch - review this\n",
        "# --\n",
        "\n",
        "try:\n",
        "    branch_name = \"main\"\n",
        "    git_checkout = subprocess.check_output([\"git\", \"checkout\", \"-t\", f\"origin/{branch_name}\"], shell=False)\n",
        "    print(git_checkout.decode(\"utf-8\") )\n",
        "except Exception as e:\n",
        "    git_checkout = subprocess.check_output([\"git\", \"checkout\",  f\"{branch_name}\"], shell=False)\n",
        "    print(git_checkout.decode(\"utf-8\") )\n",
        "\n",
        "# ---\n",
        "# git pull\n",
        "# ---\n",
        "# could be redunant if just clone, but whatever\n",
        "\n",
        "git_pull = subprocess.check_output([\"git\", \"pull\"], shell=False)\n",
        "print(git_pull.decode(\"utf-8\") )\n",
        "\n",
        "\n",
        "if repo_dir not in sys.path:\n",
        "    print(f\"adding {repo_dir} to sys.path\")\n",
        "    sys.path.extend([repo_dir])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "from urllib.request import urlopen\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import h5py\n",
        "import sys\n",
        "import requests\n",
        "import zipfile\n",
        "import inspect"
      ],
      "metadata": {
        "id": "ALYAb53bticz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "\n",
        "#file located here: https://drive.google.com/file/d/1tcVYIMcZdlDzGuJvnMtbMchKIK9ulW1P/view\n",
        "\n",
        "#make data directory if doesn't exist in path folder\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "#download meld and mosei zip files for data (mosei is from CMU, meld is friends episodes)\n",
        "!file=1tcVYIMcZdlDzGuJvnMtbMchKIK9ulW1P && wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='${file} -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"${file} -O data/data.zip && rm -rf /tmp/cookies.txt\n",
        "\n",
        "#unzip data\n",
        "!unzip data/data.zip -d data/mosei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS610PdruF33",
        "outputId": "00ade901-5493-4b1c-bf08-213d1f277f55"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-01 15:35:47--  https://docs.google.com/uc?export=download&confirm=t&id=1tcVYIMcZdlDzGuJvnMtbMchKIK9ulW1P\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.217.102, 173.194.217.138, 173.194.217.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.217.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/4b9mk72ei7v2j6c72r9suqstvrtbihqs/1648827300000/04146720491471605701/*/1tcVYIMcZdlDzGuJvnMtbMchKIK9ulW1P?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-01 15:35:48--  https://doc-08-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/4b9mk72ei7v2j6c72r9suqstvrtbihqs/1648827300000/04146720491471605701/*/1tcVYIMcZdlDzGuJvnMtbMchKIK9ulW1P?e=download\n",
            "Resolving doc-08-a8-docs.googleusercontent.com (doc-08-a8-docs.googleusercontent.com)... 173.194.216.132, 2607:f8b0:400c:c12::84\n",
            "Connecting to doc-08-a8-docs.googleusercontent.com (doc-08-a8-docs.googleusercontent.com)|173.194.216.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 326155728 (311M) [application/zip]\n",
            "Saving to: ‘data/data.zip’\n",
            "\n",
            "data/data.zip       100%[===================>] 311.05M  42.0MB/s    in 7.7s    \n",
            "\n",
            "2022-04-01 15:35:55 (40.4 MB/s) - ‘data/data.zip’ saved [326155728/326155728]\n",
            "\n",
            "Archive:  data/data.zip\n",
            "   creating: data/mosei/MELD/\n",
            "  inflating: data/mosei/MELD/test_mels.p  \n",
            "  inflating: data/mosei/MELD/valid_emotion.p  \n",
            "  inflating: data/mosei/MELD/train_sentences.p  \n",
            "  inflating: data/mosei/MELD/test_sentiment.p  \n",
            "  inflating: data/mosei/MELD/valid_mels.p  \n",
            "  inflating: data/mosei/MELD/test_emotion.p  \n",
            "  inflating: data/mosei/MELD/test_sentences.p  \n",
            "  inflating: data/mosei/MELD/valid_sentences.p  \n",
            "  inflating: data/mosei/MELD/train_emotion.p  \n",
            "  inflating: data/mosei/MELD/train_sentiment.p  \n",
            "  inflating: data/mosei/MELD/train_mels.p  \n",
            "  inflating: data/mosei/MELD/valid_sentiment.p  \n",
            "   creating: data/mosei/MOSEI/\n",
            "  inflating: data/mosei/MOSEI/README.md  \n",
            "  inflating: data/mosei/MOSEI/private_mels.p  \n",
            "  inflating: data/mosei/MOSEI/private_sentences.p  \n",
            "  inflating: data/mosei/MOSEI/test_emotion.p  \n",
            "  inflating: data/mosei/MOSEI/test_mels.p  \n",
            "  inflating: data/mosei/MOSEI/test_sentences.p  \n",
            "  inflating: data/mosei/MOSEI/test_sentiment.p  \n",
            "  inflating: data/mosei/MOSEI/train_emotion.p  \n",
            "  inflating: data/mosei/MOSEI/train_mels.p  \n",
            "  inflating: data/mosei/MOSEI/train_sentences.p  \n",
            "  inflating: data/mosei/MOSEI/train_sentiment.p  \n",
            "  inflating: data/mosei/MOSEI/valid_emotion.p  \n",
            "  inflating: data/mosei/MOSEI/valid_mels.p  \n",
            "  inflating: data/mosei/MOSEI/valid_sentences.p  \n",
            "  inflating: data/mosei/MOSEI/valid_sentiment.p  \n",
            "  inflating: data/mosei/MOSEI/train_glove.npy  \n",
            "  inflating: data/mosei/MOSEI/token_to_ix.pkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess\n",
        "\n",
        "#training data\n",
        "# print(os.getcwd())\n",
        "text_tr = pickle.load(open('data/mosei/MOSEI/train_sentences.p',\"rb\"))\n",
        "emotion_tr = pickle.load(open('data/mosei/MOSEI/train_emotion.p', \"rb\"))\n",
        "sentiment_tr = pickle.load(open('data/mosei/MOSEI/train_sentiment.p', \"rb\"))\n",
        "#change sentimement to be binary\n",
        "sentiment_tr = {k: np.sign(v) for k,v in sentiment_tr.items()}\n",
        "\n",
        "\n",
        "#valid data\n",
        "text_val = pickle.load(open('data/mosei/MOSEI/valid_sentences.p',\"rb\"))\n",
        "emotion_val = pickle.load(open('data/mosei/MOSEI/valid_emotion.p', \"rb\"))\n",
        "sentiment_val = pickle.load(open('data/mosei/MOSEI/valid_sentiment.p', \"rb\"))\n",
        "#change sentiement to be binary\n",
        "sentiment_val = {k: np.sign(v) for k,v in sentiment_val.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zSashf3uYT8",
        "outputId": "668a2904-7135-47b2-f606-21b68cce96da"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/COMP0087\n"
          ]
        }
      ]
    }
  ]
}